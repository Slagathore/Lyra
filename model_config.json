{
  "models": [
    {
      "name": "blenderllm-iq3_xxs-imat",
      "path": "G:\\AI\\Lyra\\BigModes\\BlenderLLM-IQ3_XXS-GGUF\\blenderllm-iq3_xxs-imat.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-BF16",
      "path": "G:\\AI\\Lyra\\BigModes\\ComfyUI_GGUF_windows_portable\\ComfyUI\\models\\diffusion_models\\wan2.1-i2v-14b-480p-BF16.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406833.3156478,
      "usage_count": 1
    },
    {
      "name": "Configurable-Llama-3.1-8B-Instruct-Q5_K_S",
      "path": "G:\\AI\\Lyra\\BigModes\\Llama-3.1\\Configurable-Llama-3.1-8B-Instruct-Q5_K_S.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742424948.5536733,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-aquila",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-aquila.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406836.3896465,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-baichuan",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-baichuan.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406836.671647,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-bert-bge",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-bert-bge.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406836.7686474,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-command-r",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-command-r.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406836.800647,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-deepseek-coder",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-deepseek-coder.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406836.9826467,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-deepseek-llm",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-deepseek-llm.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406837.0706472,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-falcon",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-falcon.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406837.299647,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-gpt-2",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-gpt-2.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406837.439646,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-gpt-neox",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-gpt-neox.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406837.553647,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-llama-bpe",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-llama-bpe.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406837.6656468,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-llama-spm",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-llama-spm.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.1356468,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-mpt",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-mpt.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.1936467,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-phi-3",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-phi-3.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.306648,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-qwen2",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-qwen2.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.3556464,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-refact",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-refact.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.4716465,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-starcoder",
      "path": "G:\\AI\\Lyra\\BigModes\\llama.cpp\\models\\ggml-vocab-starcoder.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406838.5856466,
      "usage_count": 2
    },
    {
      "name": "ggml-vocab-aquila",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-aquila.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-baichuan",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-baichuan.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-bert-bge",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-bert-bge.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-command-r",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-command-r.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-deepseek-coder",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-deepseek-coder.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-deepseek-llm",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-deepseek-llm.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-falcon",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-falcon.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-gpt-2",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-gpt-2.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-gpt-neox",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-gpt-neox.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-llama-bpe",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-llama-bpe.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-llama-spm",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-llama-spm.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-mpt",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-mpt.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-phi-3",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-phi-3.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-qwen2",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-qwen2.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-refact",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-refact.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "ggml-vocab-starcoder",
      "path": "G:\\AI\\Lyra\\BigModes\\node-llama-cpp-master\\llama\\llama.cpp\\models\\ggml-vocab-starcoder.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-IQ4_XS",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\DarkChampion GGUF tt\\L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-IQ4_XS.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": 8,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": 1.5,
      "last_used": 1742424780.9881005,
      "usage_count": 3
    },
    {
      "name": "L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q5_k_s",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\DarkChampion GGUF tt\\L3.2-8X4B-MOE-V2-Dark-Champion-Inst-21B-uncen-ablit-D_AU-Q5_k_s.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": 8,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": 1.5,
      "last_used": 1742424793.2679548,
      "usage_count": 2
    },
    {
      "name": "L3.1-MOE-2X8B-Dpseek-DpHermes-e32-uncen-ablit-13.7B-D_AU-Q3_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\DeepSeekDeepHermes GGUF tt\\L3.1-MOE-2X8B-Dpseek-DpHermes-e32-uncen-ablit-13.7B-D_AU-Q3_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": true,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": 1.5,
      "last_used": 1742453868.5743012,
      "usage_count": 2
    },
    {
      "name": "L3.1-MOE-2X8B-Dpseek-DpHermes-e32-uncen-ablit-13.7B-D_AU-Q6_k",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\DeepSeekDeepHermes GGUF tt\\L3.1-MOE-2X8B-Dpseek-DpHermes-e32-uncen-ablit-13.7B-D_AU-Q6_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": 1.5,
      "last_used": 1742424815.9678876,
      "usage_count": 2
    },
    {
      "name": "Qwen2.5-72B-Instruct-abliterated.i1-Q4_K_M",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-72B GGUF tt\\Qwen2.5-72B-Instruct-abliterated.i1-Q4_K_M.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.2126458,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-IQ4_XS",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-IQ4_XS.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.32165,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q2_k",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q2_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.3386474,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_l",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_l.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.354648,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.3676474,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_s",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q3_k_s.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.3816469,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q4_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q4_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.3946476,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q4_k_s",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q4_k_s.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.502647,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-q5_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-q5_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.5166476,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q5_k_s",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q5_k_s.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.5306468,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q6_k",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q6_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.543649,
      "usage_count": 1
    },
    {
      "name": "Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Qwen2.5-QwQ-35B-Eureka-3-ablit-uncen GGUF tt\\Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-D_AU-Q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742406840.650647,
      "usage_count": 1
    },
    {
      "name": "WizardLM-30B-Uncensored-Guanaco-SuperCOT-30b.i1-Q4_K_M",
      "path": "G:\\AI\\Lyra\\BigModes\\TT Models\\Wizard GGUF tt\\WizardLM-30B-Uncensored-Guanaco-SuperCOT-30b.i1-Q4_K_M.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": 1742453852.9343812,
      "usage_count": 4
    },
    {
      "name": "wan2.1-i2v-14b-480p-q2_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q2_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q3_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q3_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q4_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q4_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q4_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q4_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q4_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q4_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q5_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q5_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q5_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q5_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q5_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q5_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q6_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q6_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-480p-q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q2_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q2_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q3_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q3_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q4_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q4_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q4_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q4_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q4_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q4_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q5_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q5_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q5_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q5_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q5_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q5_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q6_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q6_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-720p-q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-i2v-14b-720p-q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q2_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q2_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q3_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q3_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q4_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q4_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q4_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q4_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q4_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q4_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q5_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q5_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q5_1",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q5_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q5_k_m",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q5_k_m.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q6_k",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q6_k.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-t2v-14b-q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1-t2v-14b-q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1_t2v_1.3b-q4_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1_t2v_1.3b-q4_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1_t2v_1.3b-q5_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1_t2v_1.3b-q5_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1_t2v_1.3b-q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1_t2v_1.3b-q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1_t2v_1.3b_fp32-f32",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan2.1_t2v_1.3b_fp32-f32.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan_2.1_vae_fp32-f16",
      "path": "G:\\AI\\Lyra\\BigModes\\wan-gguf\\wan_2.1_vae_fp32-f16.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-BF16",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-BF16.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-F16",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-F16.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q3_K_M",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q3_K_M.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q3_K_S",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q3_K_S.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q4_0",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q4_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q4_1",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q4_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q4_K_M",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q4_K_M.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q4_K_S",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q4_K_S.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q5_0",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q5_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q5_1",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q5_1.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q5_K_M",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q5_K_M.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q5_K_S",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q5_K_S.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q6_K",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q6_K.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    },
    {
      "name": "wan2.1-i2v-14b-480p-Q8_0",
      "path": "G:\\AI\\Lyra\\BigModes\\Wan2.1-I2V-14B-480P-gguf\\wan2.1-i2v-14b-480p-Q8_0.gguf",
      "type": "llama-cpp",
      "chat_format": "chatml",
      "n_gpu_layers": 35,
      "n_ctx": 4096,
      "n_batch": 512,
      "active": false,
      "description": "",
      "num_experts": null,
      "temperature": 0.8,
      "repetition_penalty": 1.06,
      "top_k": 40,
      "min_p": 0.05,
      "top_p": 0.95,
      "repeat_last_n": 64,
      "smoothing_factor": null,
      "last_used": null,
      "usage_count": 0
    }
  ]
}